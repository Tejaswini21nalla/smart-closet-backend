# -*- coding: utf-8 -*-
"""Sleeve_Length_Modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_vfM4CzE5xhj8G2p69w9oUnSMv4qR3SH
"""

from google.colab import drive
drive.mount('/content/drive')

base_dir = '/content/drive/My Drive/Data'

shape_file = '/content/drive/My Drive/Data/labels/shape/shape_anno_all.txt'

shape_columns = {
    "sleeve_length": {0: "sleeveless", 1: "short-sleeve", 2: "medium-sleeve", 3: "long-sleeve", 4: "not long-sleeve", 5: "NA"},
    "lower_clothing_length": {0: "three-point", 1: "medium short", 2: "three-quarter", 3: "long", 4: "NA"},
    "socks": {0: "no socks", 1: "socks", 2: "leggings", 3: "NA"},
    "hat": {0: "no hat", 1: "yes hat", 2: "NA"},
    "glasses": {0: "no glasses", 1: "eyeglasses", 2: "sunglasses", 3: "glasses in hand/clothes", 4: "NA"},
    "neckwear": {0: "no neckwear", 1: "yes neckwear", 2: "NA"},
    "wrist_wearing": {0: "no wristwear", 1: "yes wristwear", 2: "NA"},
    "ring": {0: "no ring", 1: "yes ring", 2: "NA"},
    "waist_accessories": {0: "no waist accessories", 1: "belt", 2: "have clothing", 3: "hidden", 4: "NA"},
    "neckline": {0: "V-shape", 1: "square", 2: "round", 3: "standing", 4: "lapel", 5: "suspenders", 6: "NA"},
    "outer_clothing_cardigan": {0: "yes cardigan", 1: "no cardigan", 2: "NA"},
    "upper_clothing_covering_navel": {0: "no", 1: "yes", 2: "NA"}
}

import pandas as pd

# Loading the shape data
shape_data = pd.read_csv(shape_file, delim_whitespace=True, header=None)
shape_data.columns = ["image_name"] + list(shape_columns.keys())

# Remove rows where 'sleeve_length' is 'NA'
cleaned_data = shape_data[shape_data['sleeve_length'] != 'NA']

# Count occurrences of each class in 'sleeve_length'
sleeve_length_counts = cleaned_data['sleeve_length'].value_counts()

# Display the counts
print("Counts of each class in 'sleeve_length':")
print(sleeve_length_counts)

cleaned_data.head()

from sklearn.model_selection import train_test_split
sleeve_length_data = cleaned_data[["image_name", "sleeve_length"]]

sleeve_length_data.head()

# Remove rows where 'sleeve_length_encoded' is 4 or 5
filtered_data = sleeve_length_data[~sleeve_length_data['sleeve_length'].isin([4, 5])]

# Display the shape and first few rows of the filtered data
print(f"Filtered data shape: {filtered_data.shape}")
print(filtered_data.head())

sleeve_length_counts_1 = filtered_data['sleeve_length'].value_counts()

# Display the counts
print("Counts of each class in 'sleeve_length':")
print(sleeve_length_counts_1)

"""# Modelling

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.preprocessing import image

img_dir = base_dir + '/images/'

# Function to extract features from images
def extract_features(image_paths):
    model = VGG16(weights='imagenet', include_top=False, pooling='avg')
    feature_list = []
    missing_images = []  # List to keep track of missing images

    for img_path in image_paths:
        try:
            img = image.load_img(img_dir + img_path, target_size=(224, 224))  # Resize image
            img_array = image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
            img_array = preprocess_input(img_array)  # Preprocess for VGG16
            features = model.predict(img_array)
            feature_list.append(features.flatten())  # Flatten the features
        except Exception as e:
            print(f"Could not load image: {img_path} - {str(e)}")
            missing_images.append(img_path)

    print(f"Total missing images: {len(missing_images)}")
    return np.array(feature_list), missing_images

# Create a DataFrame for the features
image_paths = filtered_data['image_name'].values
sleeve_lengths = filtered_data['sleeve_length'].values

# Count how many images exist for each class (sleeve length) before extraction
class_counts_before = pd.Series(sleeve_lengths).value_counts()
print("Class distribution for sleeve lengths before extraction:")
print(class_counts_before)

# Extract features for the images
X_features, missing_images = extract_features(image_paths)

# Create a DataFrame for features
X = pd.DataFrame(X_features)

# Filter sleeve lengths for images that were successfully loaded
valid_image_indices = [i for i, img_path in enumerate(image_paths) if img_path not in missing_images]
y = sleeve_lengths[valid_image_indices]

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Show class counts after extraction
class_counts_after = pd.Series(y_train).value_counts()
print("Class distribution for sleeve lengths after extraction:")
print(class_counts_after)

from sklearn.metrics import classification_report, accuracy_score

def evaluate_model(model, X_train, y_train, X_test, y_test):
    # Fit the model
    model.fit(X_train, y_train)

    # Predict on training and test sets
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    # Calculate accuracies
    train_accuracy = accuracy_score(y_train, y_train_pred)
    test_accuracy = accuracy_score(y_test, y_test_pred)

    print(f"Training Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

    print("Training Classification Report:")
    print(classification_report(y_train, y_train_pred))

    print("Test Classification Report:")
    print(classification_report(y_test, y_test_pred))

    return train_accuracy, test_accuracy

# Decision Tree without Sampling
dt_model = DecisionTreeClassifier(random_state=42)
print("Decision Tree without Sampling:")
evaluate_model(dt_model, X_train, y_train, X_test, y_test)

# Decision Tree with Oversampling
from imblearn.over_sampling import RandomOverSampler
oversampler = RandomOverSampler(random_state=42)
X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)

print("Decision Tree with Oversampling:")
evaluate_model(dt_model, X_train_over, y_train_over, X_test, y_test)

# Decision Tree Hyperparameter Tuning
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)
dt_grid_search.fit(X_train, y_train)
print("Best parameters for Decision Tree:", dt_grid_search.best_params_)

print("Evaluating Best Decision Tree Model:")
evaluate_model(dt_grid_search, X_train, y_train, X_test, y_test)

from imblearn.under_sampling import RandomUnderSampler
oversampler = RandomOverSampler(random_state=42)
undersampler = RandomUnderSampler(random_state=42)

# Oversample the minority class
X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)

# Undersample the majority class
X_train_balanced, y_train_balanced = undersampler.fit_resample(X_train_over, y_train_over)

# Evaluate the Best Decision Tree Model on Resampled Data
print("Evaluating Best Decision Tree Model with Balanced Data:")
evaluate_model(dt_grid_search.best_estimator_, X_train_balanced, y_train_balanced, X_test, y_test)

"""# Random Forest"""

rf_model = RandomForestClassifier(random_state=42)
print("Random Forest without Sampling:")
evaluate_model(rf_model, X_train, y_train, X_test, y_test)

oversampler = RandomOverSampler(random_state=42)
X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)
print("Random Forest with Oversampling:")
evaluate_model(rf_model, X_train_over, y_train_over, X_test, y_test)

param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)
rf_grid_search.fit(X_train, y_train)
print("Best parameters for Random Forest:", rf_grid_search.best_params_)

print("Evaluating Best Random Forest Model:")
evaluate_model(rf_grid_search, X_train, y_train, X_test, y_test)

X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)

# Undersample the majority class
undersampler = RandomUnderSampler(random_state=42)
X_train_balanced, y_train_balanced = undersampler.fit_resample(X_train_over, y_train_over)

# Step 5: Evaluate the Best Random Forest Model on Resampled Data
print("Evaluating Best Random Forest Model with Balanced Data:")
evaluate_model(rf_grid_search.best_estimator_, X_train_balanced, y_train_balanced, X_test, y_test)

"""# Boosting"""

from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
# AdaBoost without Sampling
ada_model = AdaBoostClassifier(random_state=42)
print("AdaBoost without Sampling:")
evaluate_model(ada_model, X_train, y_train, X_test, y_test)

# AdaBoost with Oversampling
oversampler = RandomOverSampler(random_state=42)
X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)
print("AdaBoost with Oversampling:")
evaluate_model(ada_model, X_train_over, y_train_over, X_test, y_test)

# AdaBoost Hyperparameter Tuning
param_grid_ada = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 1.0]
}
ada_grid_search = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid_ada, cv=5)
ada_grid_search.fit(X_train, y_train)
print("Best parameters for AdaBoost:", ada_grid_search.best_params_)

print("Evaluating Best Ada Boost Model:")
evaluate_model(ada_grid_search, X_train, y_train, X_test, y_test)

import os

# Function to filter available image paths
def filter_available_images(image_paths, img_dir):
    available_images = []
    available_labels = []

    for img_path, label in zip(image_paths, sleeve_lengths):
        if os.path.isfile(os.path.join(img_dir, img_path)):
            available_images.append(img_path)
            available_labels.append(label)

    return np.array(available_images), np.array(available_labels)

# Filter the image paths
filtered_image_paths, filtered_labels = filter_available_images(image_paths, img_dir)

# Extract features for the available images
X_features, missing_images = extract_features(filtered_image_paths)

# Create a DataFrame for features
X = pd.DataFrame(X_features)

# Ensure the labels correspond to the valid images loaded
y = filtered_labels[~np.isin(filtered_image_paths, missing_images)]

import numpy as np
import pandas as pd
import os

# Keras and TensorFlow imports
from keras.models import Model
from keras.layers import Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.preprocessing import image
from keras.applications import VGG16, ResNet50, InceptionV3, DenseNet121, MobileNet, EfficientNetB0
from keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def build_cnn_model():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze the base model
    for layer in base_model.layers:
        layer.trainable = False

    # Create a new model on top
    x = base_model.output
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(len(np.unique(sleeve_lengths)), activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    return model

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_reshaped = X_train.values.reshape(3732, 224, 224, 3)

print(X.shape)

# Build the model
model = build_cnn_model()

# Compile the model
model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(train_generator, epochs=10, validation_data=validation_generator)

# Assuming you have a validation generator set up
val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}")

"""# CNN"""

from sklearn.utils import resample

# Separate each class into different DataFrames
class_0 = filtered_data[filtered_data['sleeve_length'] == 0]
class_1 = filtered_data[filtered_data['sleeve_length'] == 1]
class_3 = filtered_data[filtered_data['sleeve_length'] == 3]
class_2 = filtered_data[filtered_data['sleeve_length'] == 2]

target_count = 5000

# Downsample classes 0, 1, and 3 to match the target count
class_0_downsampled = resample(class_0, replace=False, n_samples=target_count, random_state=42)
class_1_downsampled = resample(class_1, replace=False, n_samples=target_count, random_state=42)
class_3_downsampled = resample(class_3, replace=False, n_samples=target_count, random_state=42)

# Combine downsampled classes with class 2 to create a balanced dataset
balanced_data = pd.concat([class_0_downsampled, class_1_downsampled, class_3_downsampled, class_2])

# Shuffle the balanced dataset
balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)

# Display the counts of each class to verify balance
sleeve_length_counts_balanced = balanced_data['sleeve_length'].value_counts()
print("Counts of each class in balanced 'sleeve_length':")
print(sleeve_length_counts_balanced)

import os
image_dir = '/content/drive/My Drive/Data/images/'

balanced_data['image_path'] = balanced_data['image_name'].apply(lambda x: os.path.join(image_dir, x))
balanced_data = balanced_data[balanced_data['image_path'].apply(os.path.exists)]
print(f"Valid images found: {balanced_data.shape[0]}")

sleeve_length_counts_balanced = balanced_data['sleeve_length'].value_counts()
print("Counts of each class in balanced 'sleeve_length':")
print(sleeve_length_counts_balanced)

image_paths = [os.path.join(image_dir, img_name) for img_name in balanced_data['image_name']]
labels = balanced_data['sleeve_length'].values

train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)

import pandas as pd
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model

# Convert labels to strings as ImageDataGenerator requires string labels
train_labels = [str(label) for label in train_labels]
test_labels = [str(label) for label in test_labels]

# Set up data generators
IMG_SIZE = 224
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalizing pixel values between 0 and 1
    horizontal_flip=True,
    rotation_range=20,
    zoom_range=0.15
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(
    pd.DataFrame({'filename': train_paths, 'class': train_labels}),
    x_col='filename',
    y_col='class',
    target_size=(IMG_SIZE, IMG_SIZE),
    class_mode='categorical',
    batch_size=BATCH_SIZE
)

test_generator = test_datagen.flow_from_dataframe(
    pd.DataFrame({'filename': test_paths, 'class': test_labels}),
    x_col='filename',
    y_col='class',
    target_size=(IMG_SIZE, IMG_SIZE),
    class_mode='categorical',
    batch_size=BATCH_SIZE
)

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(4, activation='softmax')(x)  # 4 classes (0, 1, 2, 3)

model = Model(inputs=base_model.input, outputs=predictions)

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
EPOCHS = 20
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=test_generator
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")



"""# Resnet50"""

import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torch import nn, optim
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

from sklearn.utils import resample
import pandas as pd

# Separate each class into different DataFrames
class_0 = filtered_data[filtered_data['sleeve_length'] == 0]
class_1 = filtered_data[filtered_data['sleeve_length'] == 1]
class_3 = filtered_data[filtered_data['sleeve_length'] == 3]
class_2 = filtered_data[filtered_data['sleeve_length'] == 2]

# Set the target count for each class
target_count = 7000

# Downsample classes 0, 1, and 3 to the target count
class_0_downsampled = resample(class_0, replace=False, n_samples=target_count, random_state=42)
class_1_downsampled = resample(class_1, replace=False, n_samples=target_count, random_state=42)
class_3_downsampled = resample(class_3, replace=False, n_samples=target_count, random_state=42)

# Combine downsampled classes with class 2 to create a partially balanced dataset
partial_balanced_data = pd.concat([class_0_downsampled, class_1_downsampled, class_3_downsampled, class_2])

# Shuffle the partially balanced dataset
partial_balanced_data = partial_balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)

# Check class distribution to verify
print("Counts of each class in partially balanced 'sleeve_length':")
print(partial_balanced_data['sleeve_length'].value_counts())

from torch.utils.data import Dataset
from PIL import Image
import os
from torchvision import transforms

# Define the standard and class-specific transformations
standard_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.RandomResizedCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Define the augmentation for class 2 to add more variation
class_2_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),
    transforms.RandomResizedCrop(224),
    transforms.RandomGrayscale(p=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

class CustomImageDataset(Dataset):
    def __init__(self, dataframe, img_dir):
        self.dataframe = dataframe
        self.img_dir = img_dir

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx]['image_path']
        image = Image.open(img_path).convert("RGB")
        label = self.dataframe.iloc[idx]['sleeve_length']

        # Apply specific augmentation for class 2
        if label == 2:
            image = class_2_transforms(image)
        else:
            image = standard_transforms(image)

        return image, label

image_dir = '/content/drive/My Drive/Data/images/'

# Add full paths to images and filter only those that exist
partial_balanced_data['image_path'] = partial_balanced_data['image_name'].apply(lambda x: os.path.join(image_dir, x))
partial_balanced_data = partial_balanced_data[partial_balanced_data['image_path'].apply(os.path.exists)]

print(f"Valid images found: {partial_balanced_data.shape[0]}")

# Split the data into train and test sets
train_data, test_data = train_test_split(partial_balanced_data, test_size=0.2, stratify=partial_balanced_data['sleeve_length'], random_state=42)

print("Training set class distribution:")
print(train_data['sleeve_length'].value_counts())

print("\nTesting set class distribution:")
print(test_data['sleeve_length'].value_counts())

from torch.utils.data import DataLoader
# Create the training and test datasets
train_dataset = CustomImageDataset(train_data, img_dir=image_dir)
test_dataset = CustomImageDataset(test_data, img_dir=image_dir)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Load pretrained ResNet
model = models.resnet50(pretrained=True)
num_classes = balanced_data['sleeve_length'].nunique()
model.fc = nn.Linear(model.fc.in_features, num_classes)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 50

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    running_corrects = 0
    total_samples = 0

    print(f"Epoch {epoch + 1}/{num_epochs}")
    print("-" * 30)

    for batch_idx, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward pass and optimize
        loss.backward()
        optimizer.step()

        # Track the loss
        running_loss += loss.item()

        # Calculate accuracy
        _, preds = torch.max(outputs, 1)
        running_corrects += torch.sum(preds == labels).item()
        total_samples += labels.size(0)

        # Log progress for every 10 batches
        if (batch_idx + 1) % 10 == 0:
            batch_accuracy = running_corrects / total_samples * 100
            print(f"Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.2f}%")

    # Average loss and accuracy for the epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = running_corrects / total_samples * 100
    print(f"Epoch {epoch + 1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%")
    print("=" * 30)

from sklearn.metrics import classification_report

def evaluate_model(data_loader):
    model.eval()
    all_labels = []
    all_preds = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())

    return np.array(all_labels), np.array(all_preds)

# Evaluate on train set
train_labels, train_preds = evaluate_model(train_loader)
print("Training Set Performance:")
print(classification_report(train_labels, train_preds))

# Evaluate on test set
test_labels, test_preds = evaluate_model(test_loader)
print("Test Set Performance:")
print(classification_report(test_labels, test_preds))

import seaborn as sns
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Confusion Matrix
def plot_confusion_matrix(true_labels, pred_labels, title):
    conf_matrix = confusion_matrix(true_labels, pred_labels)
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(title)
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.show()

# Plot confusion matrices
plot_confusion_matrix(train_labels, train_preds, "Confusion Matrix - Training Set")
plot_confusion_matrix(test_labels, test_preds, "Confusion Matrix - Test Set")

# ROC Curve and AUC
def plot_roc(true_labels, pred_labels, num_classes):
    true_bin = label_binarize(true_labels, classes=range(num_classes))
    pred_bin = label_binarize(pred_labels, classes=range(num_classes))
    plt.figure()
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(true_bin[:, i], pred_bin[:, i])
        auc_score = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"Class {i} (AUC = {auc_score:.2f})")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title("ROC Curve")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend()
    plt.show()

# Plot ROC curves
plot_roc(test_labels, test_preds, num_classes)

import torch


torch.save(model.state_dict(), 'sleeve_model_10.pth')

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from google.colab import files
from PIL import Image


model = models.resnet50(pretrained=False)
num_classes = 4
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Load the saved model parameters
model.load_state_dict(torch.load('sleeve_model_10.pth'))
model.eval()  # Set the model to evaluation mode

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

uploaded = files.upload()
for filename in uploaded.keys():
    image = Image.open(filename)
    print(f"Image '{filename}' uploaded successfully")

preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

image_tensor = preprocess(image).unsqueeze(0).to(device)

with torch.no_grad():
    output = model(image_tensor)
    _, predicted_class = torch.max(output, 1)

class_labels = {0: "sleeveless", 1: "short-sleeve", 2: "medium-sleeve", 3: "long-sleeve"}
predicted_label = class_labels[predicted_class.item()]
print(f"Predicted label: {predicted_label}")