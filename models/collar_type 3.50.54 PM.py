# -*- coding: utf-8 -*-
"""Collar_Type.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mL3c_xNHkQZm9Mxgi-jgoo7i2l29vkei
"""

from google.colab import drive
drive.mount('/content/drive')

base_dir = '/content/drive/My Drive/Data'

shape_file = base_dir + '/labels/shape/shape_anno_all.txt'

shape_columns = {
    "sleeve_length": {0: "sleeveless", 1: "short-sleeve", 2: "medium-sleeve", 3: "long-sleeve", 4: "not long-sleeve", 5: "NA"},
    "lower_clothing_length": {0: "three-point", 1: "medium short", 2: "three-quarter", 3: "long", 4: "NA"},
    "socks": {0: "no socks", 1: "socks", 2: "leggings", 3: "NA"},
    "hat": {0: "no hat", 1: "yes hat", 2: "NA"},
    "glasses": {0: "no glasses", 1: "eyeglasses", 2: "sunglasses", 3: "glasses in hand/clothes", 4: "NA"},
    "neckwear": {0: "no neckwear", 1: "yes neckwear", 2: "NA"},
    "wrist_wearing": {0: "no wristwear", 1: "yes wristwear", 2: "NA"},
    "ring": {0: "no ring", 1: "yes ring", 2: "NA"},
    "waist_accessories": {0: "no waist accessories", 1: "belt", 2: "have clothing", 3: "hidden", 4: "NA"},
    "neckline": {0: "V-shape", 1: "square", 2: "round", 3: "standing", 4: "lapel", 5: "suspenders", 6: "NA"},
    "outer_clothing_cardigan": {0: "yes cardigan", 1: "no cardigan", 2: "NA"},
    "upper_clothing_covering_navel": {0: "no", 1: "yes",2:"NA"}
}

import pandas as pd
shape_data = pd.read_csv(shape_file, delim_whitespace=True, header=None)
shape_data.columns = ["image_name"] + list(shape_columns.keys())

cleaned_data = shape_data[shape_data['neckline']!='NA']

neckline_counts = cleaned_data['neckline'].value_counts()
print("Count of each class in neck line")
print(neckline_counts)

from sklearn.model_selection import train_test_split
neckline_data = cleaned_data[['image_name','neckline']]

neckline_data.head()

import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torch import nn, optim
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

#Separate each class into different DataFrames
class_0 = neckline_data[neckline_data['neckline'] == 0]
class_1 = neckline_data[neckline_data['neckline'] == 1]
class_3 = neckline_data[neckline_data['neckline'] == 3]
class_2 = neckline_data[neckline_data['neckline'] == 2]
class_4 = neckline_data[neckline_data['neckline'] == 4]
class_5 = neckline_data[neckline_data['neckline'] == 5]
class_6 = neckline_data[neckline_data['neckline'] == 6]

target_count = 14000  # Target sample size for each class

# Downsample classes keeping class 1,3 as-is for augmentation
class_2_downsampled = resample(class_2, replace=False, n_samples=target_count, random_state=42)
class_6_downsampled = resample(class_6, replace=False, n_samples=target_count, random_state=42)


# Combine all classes
balanced_data = pd.concat([class_0, class_1, class_2_downsampled, class_3,class_4,class_5,class_6_downsampled])

# Add full paths for images
image_dir = '/content/drive/My Drive/Data/images/'  # Update with your directory path
balanced_data['image_path'] = balanced_data['image_name'].apply(lambda x: os.path.join(image_dir, x))
balanced_data = balanced_data[balanced_data['image_path'].apply(os.path.exists)]

print(balanced_data['neckline'].value_counts())

from torch.utils.data import Dataset
from PIL import Image
import os
from torchvision import transforms

# Define the standard and class-specific transformations
standard_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.RandomResizedCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Define the augmentation for class 2 to add more variation
class_1_3_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),
    transforms.RandomResizedCrop(224),
    transforms.RandomGrayscale(p=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

class CustomImageDataset(Dataset):
    def __init__(self, dataframe, img_dir):
        self.dataframe = dataframe
        self.img_dir = img_dir

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx]['image_path']
        image = Image.open(img_path).convert("RGB")
        label = self.dataframe.iloc[idx]['neckline']

        # Apply specific augmentation for class 2
        if label == 1 or label == 3:
            image = class_1_3_transforms(image)
        else:
            image = standard_transforms(image)

        return image, label

# Split the data into train and test sets
train_data, test_data = train_test_split(balanced_data, test_size=0.2, stratify=balanced_data['neckline'], random_state=42)

print("Training set class distribution:")
print(train_data['neckline'].value_counts())

print("\nTesting set class distribution:")
print(test_data['neckline'].value_counts())

from torch.utils.data import DataLoader
# Create the training and test datasets
train_dataset = CustomImageDataset(train_data, img_dir=image_dir)
test_dataset = CustomImageDataset(test_data, img_dir=image_dir)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

model = models.resnet50(pretrained=True)
num_classes = balanced_data['neckline'].nunique()
model.fc = nn.Linear(model.fc.in_features, num_classes)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    running_corrects = 0
    total_samples = 0

    print(f"Epoch {epoch + 1}/{num_epochs}")
    print("-" * 30)

    for batch_idx, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # Backward pass and optimize
        loss.backward()
        optimizer.step()

        # Track the loss
        running_loss += loss.item()

        # Calculate accuracy
        _, preds = torch.max(outputs, 1)
        running_corrects += torch.sum(preds == labels).item()
        total_samples += labels.size(0)

        # Log progress for every 10 batches
        if (batch_idx + 1) % 10 == 0:
            batch_accuracy = running_corrects / total_samples * 100
            print(f"Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.2f}%")

    # Average loss and accuracy for the epoch
    epoch_loss = running_loss / len(train_loader)
    epoch_accuracy = running_corrects / total_samples * 100
    print(f"Epoch {epoch + 1} Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%")
    print("=" * 30)

from sklearn.metrics import classification_report

def evaluate_model(data_loader):
    model.eval()
    all_labels = []
    all_preds = []

    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())

    return np.array(all_labels), np.array(all_preds)

# Evaluate on train set
train_labels, train_preds = evaluate_model(train_loader)
print("Training Set Performance:")
print(classification_report(train_labels, train_preds))

# Evaluate on test set
test_labels, test_preds = evaluate_model(test_loader)
print("Test Set Performance:")
print(classification_report(test_labels, test_preds))

import seaborn as sns
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Confusion Matrix
def plot_confusion_matrix(true_labels, pred_labels, title):
    conf_matrix = confusion_matrix(true_labels, pred_labels)
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(title)
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.show()

# Plot confusion matrices
plot_confusion_matrix(train_labels, train_preds, "Confusion Matrix - Training Set")
plot_confusion_matrix(test_labels, test_preds, "Confusion Matrix - Test Set")

# ROC Curve and AUC
def plot_roc(true_labels, pred_labels, num_classes):
    true_bin = label_binarize(true_labels, classes=range(num_classes))
    pred_bin = label_binarize(pred_labels, classes=range(num_classes))
    plt.figure()
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(true_bin[:, i], pred_bin[:, i])
        auc_score = auc(fpr, tpr)
        plt.plot(fpr, tpr, label=f"Class {i} (AUC = {auc_score:.2f})")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title("ROC Curve")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend()
    plt.show()

# Plot ROC curves
plot_roc(test_labels, test_preds, num_classes)

import torch


torch.save(model.state_dict(), 'collar_model_10.pth')

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from google.colab import files
from PIL import Image

# Step 1: Load the saved model for inference
# Define the model architecture and modify the final layer to match the number of classes
model = models.resnet50(pretrained=False)
num_classes = 7
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Load the saved model parameters
model.load_state_dict(torch.load('collar_model_10.pth'))
model.eval()  # Set the model to evaluation mode

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Step 2: Upload an image in Google Colab
uploaded = files.upload()
for filename in uploaded.keys():
    image = Image.open(filename)
    print(f"Image '{filename}' uploaded successfully")

# Step 3: Preprocess the uploaded image
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

image_tensor = preprocess(image).unsqueeze(0).to(device)

# Step 4: Make a prediction
with torch.no_grad():
    output = model(image_tensor)
    _, predicted_class = torch.max(output, 1)

# Step 5: Map the prediction to class labels
class_labels = {0: "V-shape", 1: "square", 2: "round", 3: "standing", 4: "lapel", 5: "suspenders", 6: "NA"}
predicted_label = class_labels[predicted_class.item()]
print(f"Predicted label: {predicted_label}")